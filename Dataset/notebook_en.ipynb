{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Ali Bazrkar - Iran Weather EDA**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "621cacfafabf5af8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "In an ever-changing world where weather patterns significantly impact our daily lives, understanding the climate is more important than ever. This exploratory data analysis project delves into the weather data from various cities across Iran, spanning from 2011 (1390) to the present. Using data sourced from **Open-Meteo**, we aim to uncover meaningful insights that can help us better understand regional weather dynamics.\n",
    "\n",
    "The significance of this analysis extends beyond mere statistics; it has the potential to inform agricultural practices, guide urban planning, and enhance disaster preparedness. By exploring key factors such as temperature variations, precipitation patterns, and wind dynamics, we can paint a comprehensive picture of how climate trends evolve over time.\n",
    "\n",
    "As an artist specializing in pixel, digital, and portrait art, my passion for mathematics—particularly calculus, probability, and statistics—has driven me to explore the fascinating world of artificial intelligence. My journey into machine learning began about a year ago when I encountered GANs and GPTs, sparking a desire to learn how these technologies create and analyze data.\n",
    "\n",
    "Throughout this notebook, we will engage in a structured exploration of the dataset, starting with data visualization to identify trends and anomalies. We will then dive into detailed analyses, uncovering correlations and patterns that may have significant implications. Whether you’re a researcher, policymaker, or simply a curious observer, this analysis aims to present the findings in an accessible and engaging manner, ensuring you stay intrigued every step of the way.\n",
    "\n",
    "This project serves as my final Data Analysis project for the **Tehran Institute of Technology - MFT** program, allowing me to apply my achieved skills in a meaningful way. Join me on this journey as we uncover the stories hidden within the data and explore the world of Iran's weather patterns!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "552494302a76cc2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dec44e95f248e07b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from persiantools.jdatetime import JalaliDate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T18:47:31.374686300Z",
     "start_time": "2024-09-27T18:47:31.339298200Z"
    }
   },
   "id": "e8a26f389e24d072"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d19b24e3c533172"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c15e392499843c8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Dataset/Geography Information.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m geography \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDataset/Geography Information.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m geography[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcity\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m geography[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcity\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(geography)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m   1014\u001B[0m     dialect,\n\u001B[0;32m   1015\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m   1023\u001B[0m )\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'Dataset/Geography Information.csv'"
     ]
    }
   ],
   "source": [
    "geography = pd.read_csv(f\"Dataset/Geography Information.csv\")\n",
    "geography['city'] = geography['city'].str.strip()\n",
    "print(geography)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T18:47:35.536626800Z",
     "start_time": "2024-09-27T18:47:34.650675200Z"
    }
   },
   "id": "41b4e4c44957f093"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# City name lists\n",
    "cities = [\n",
    "    \"Tehran\",\n",
    "    \"Karaj\",\n",
    "    \"Tabriz\",\n",
    "    \"Mashhad\",\n",
    "    \"Isfahan\",\n",
    "    \"Shiraz\",\n",
    "    \"Kerman\",\n",
    "    \"Ahvaz\",\n",
    "    \"Bandar Abbas\",\n",
    "    \"Rasht\"\n",
    "]\n",
    "\n",
    "# list to keep dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Reading DataFrames and Saving them in a dictionary\n",
    "for city in cities:\n",
    "    df = pd.read_csv(f\"Dataset/{city}.csv\")\n",
    "    df['city'] = city\n",
    "    dataframes.append(df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b824d8beb307944e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset Combining "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cb8a6e2d88b70c8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df_combined = pd.concat(dataframes, ignore_index=True)\n",
    "df_combined = pd.merge(df_combined, geography, on='city', how='left')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "398605d7a7df1a9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "373bdb6b9980c4b2"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "del df, df_combined, dataframes, geography, cities\n",
    "df = pd.read_csv(\"Dataset/Combined Dataset.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd72ed25c55d259f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking NaNs "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f80867947f3e0826"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Missing Values:\n",
      "time                               0\n",
      "temp_max (°C)                      0\n",
      "temp_min (°C)                      0\n",
      "temp_mean (°C)                     0\n",
      "daylight_duration (s)              0\n",
      "precipitation_sum (mm)             0\n",
      "rain_sum (mm)                      0\n",
      "snowfall_sum (cm)                  0\n",
      "precipitation_hours (h)            0\n",
      "wind_speed_max (km/h)              0\n",
      "wind_gusts_max (km/h)              0\n",
      "wind_direction_dominant (°)        0\n",
      "shortwave_radiation_sum (MJ/m²)    0\n",
      "evapotranspiration (mm)            0\n",
      "city                               0\n",
      "latitude                           0\n",
      "longitude                          0\n",
      "elevation                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Missing Values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e59725dcf5d7a5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gregorian and Jalali Date Settings "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6849f78f3a8e8cb0"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df[\"time\"] = pd.to_datetime(df[\"time\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a0ef20ffe4b1264"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# create Jalali date column\n",
    "df[\"date_jalali\"] = df[\"time\"].apply(lambda time: JalaliDate(time)) \n",
    "\n",
    "# rename time to date_gregorian\n",
    "df.rename(columns={'time': 'date'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f9ac6f3419327bc"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "df[\"year\"] = df[\"date_jalali\"].apply(lambda date: date.year)\n",
    "df[\"month\"] = df[\"date_jalali\"].apply(lambda date: date.month)\n",
    "df[\"season\"] = df[\"month\"].apply(lambda month:\n",
    "                                    \"Spring\" if month in [1, 2, 3] else \n",
    "                                    \"Summer\" if month in [4, 5, 6] else \n",
    "                                    \"Autumn\" if month in [7, 8, 9] else \n",
    "                                    \"Winter\")\n",
    "df['month'] = df['month'].map({\n",
    "    1: \"Farvardin\",\n",
    "    2: \"Ordibehesht\",\n",
    "    3: \"Khordad\",\n",
    "    4: \"Tir\",\n",
    "    5: \"Mordad\",\n",
    "    6: \"Shahrivar\",\n",
    "    7: \"Mehr\",\n",
    "    8: \"Aban\",\n",
    "    9: \"Azar\",\n",
    "    10: \"Dey\",\n",
    "    11: \"Bahman\",\n",
    "    12: \"Esfand\"\n",
    "})\n",
    "\n",
    "df.drop(columns=\"date_jalali\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b650291e8862d61b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adjusting Units"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f82cb9e9efb6eb6"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df[\"snowfall_sum (cm)\"] = df[\"snowfall_sum (cm)\"].apply(lambda item : item * 10)\n",
    "df.rename(columns={'snowfall_sum (cm)': 'snowfall_sum (mm)'}, inplace=True)\n",
    "\n",
    "df[\"daylight_duration (s)\"] = df[\"daylight_duration (s)\"].apply(lambda item : item / 3600)\n",
    "df.rename(columns={'daylight_duration (s)': 'daylight_duration (h)'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ac4f1722df1bff6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GeoPandas Data Additions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27e5d4ee2cbde6e1"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "city_to_province = {\n",
    "    'Tehran': 'Tehran',\n",
    "    'Tabriz': 'East Azerbaijan',\n",
    "    'Mashhad': 'Razavi Khorasan',\n",
    "    'Isfahan': 'Isfahan',\n",
    "    'Shiraz': 'Fars',\n",
    "    'Ahvaz': 'Khuzestan',\n",
    "    'Rasht': 'Gilan',\n",
    "    'Kerman': 'Kerman',\n",
    "    'Bandar Abbas': 'Hormozgan',\n",
    "    'Karaj': 'Alborz',\n",
    "}\n",
    "\n",
    "# Step 2: Add a province column to the DataFrame\n",
    "df['province'] = df['city'].map(city_to_province)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "763c7e297f327d7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Additional Columns for Easier Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f32c5edb9fb921cc"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df[\"temp_diff (°C)\"] = df[\"temp_max (°C)\"] - df[\"temp_min (°C)\"]\n",
    "df[\"remain_precipitation (mm)\"] = df[\"precipitation_sum (mm)\"] - df[\"evapotranspiration (mm)\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76f2eff83ad04dd"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49260 entries, 0 to 49259\n",
      "Data columns (total 25 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   date_gregorian                   49260 non-null  datetime64[ns]\n",
      " 1   temp_max (°C)                    49260 non-null  float64       \n",
      " 2   temp_min (°C)                    49260 non-null  float64       \n",
      " 3   temp_mean (°C)                   49260 non-null  float64       \n",
      " 4   daylight_duration (h)            49260 non-null  float64       \n",
      " 5   precipitation_sum (mm)           49260 non-null  float64       \n",
      " 6   rain_sum (mm)                    49260 non-null  float64       \n",
      " 7   snowfall_sum (mm)                49260 non-null  float64       \n",
      " 8   precipitation_hours (h)          49260 non-null  float64       \n",
      " 9   wind_speed_max (km/h)            49260 non-null  float64       \n",
      " 10  wind_gusts_max (km/h)            49260 non-null  float64       \n",
      " 11  wind_direction_dominant (°)      49260 non-null  int64         \n",
      " 12  shortwave_radiation_sum (MJ/m²)  49260 non-null  float64       \n",
      " 13  evapotranspiration (mm)          49260 non-null  float64       \n",
      " 14  city                             49260 non-null  object        \n",
      " 15  latitude                         49260 non-null  float64       \n",
      " 16  longitude                        49260 non-null  float64       \n",
      " 17  elevation                        49260 non-null  float64       \n",
      " 18  date_jalali                      49260 non-null  object        \n",
      " 19  year                             49260 non-null  int64         \n",
      " 20  month                            49260 non-null  object        \n",
      " 21  season                           49260 non-null  object        \n",
      " 22  province                         49260 non-null  object        \n",
      " 23  temp_diff (°C)                   49260 non-null  float64       \n",
      " 24  remain_precipitation (mm)        49260 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(17), int64(2), object(5)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "780839923c0b0874"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Memory Cleaning "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "135d7e7575797502"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def datatype_cleaner(df):\n",
    "    \n",
    "    for column in df.select_dtypes(include=['float', 'int']).columns:\n",
    "        min_val = df[column].min()\n",
    "        max_val = df[column].max()\n",
    "    \n",
    "        col_dtype = df[column].dtype\n",
    "    \n",
    "        # Check ranges for int and float types\n",
    "        if np.issubdtype(col_dtype, np.floating):\n",
    "            if min_val >= -65504 and max_val <= 65504:  # float16\n",
    "                df[column] = df[column].astype(np.float16)\n",
    "            elif min_val >= -3.4e38 and max_val <= 3.4e38:  # float32\n",
    "                df[column] = df[column].astype(np.float32)\n",
    "            else:\n",
    "                df[column] = df[column].astype(np.float64)\n",
    "    \n",
    "        elif np.issubdtype(col_dtype, np.integer):\n",
    "            if min_val >= -128 and max_val <= 127:  # int8\n",
    "                df[column] = df[column].astype(np.int8)\n",
    "            elif min_val >= -32768 and max_val <= 32767:  # int16\n",
    "                df[column] = df[column].astype(np.int16)\n",
    "            elif min_val >= -2147483648 and max_val <= 2147483647:  # int32\n",
    "                df[column] = df[column].astype(np.int32)\n",
    "            else:\n",
    "                df[column] = df[column].astype(np.int64)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9214323913a4ea0"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49260 entries, 0 to 49259\n",
      "Data columns (total 25 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   date_gregorian                   49260 non-null  datetime64[ns]\n",
      " 1   temp_max (°C)                    49260 non-null  float16       \n",
      " 2   temp_min (°C)                    49260 non-null  float16       \n",
      " 3   temp_mean (°C)                   49260 non-null  float16       \n",
      " 4   daylight_duration (h)            49260 non-null  float16       \n",
      " 5   precipitation_sum (mm)           49260 non-null  float16       \n",
      " 6   rain_sum (mm)                    49260 non-null  float16       \n",
      " 7   snowfall_sum (mm)                49260 non-null  float16       \n",
      " 8   precipitation_hours (h)          49260 non-null  float16       \n",
      " 9   wind_speed_max (km/h)            49260 non-null  float16       \n",
      " 10  wind_gusts_max (km/h)            49260 non-null  float16       \n",
      " 11  wind_direction_dominant (°)      49260 non-null  int16         \n",
      " 12  shortwave_radiation_sum (MJ/m²)  49260 non-null  float16       \n",
      " 13  evapotranspiration (mm)          49260 non-null  float16       \n",
      " 14  city                             49260 non-null  object        \n",
      " 15  latitude                         49260 non-null  float16       \n",
      " 16  longitude                        49260 non-null  float16       \n",
      " 17  elevation                        49260 non-null  float16       \n",
      " 18  date_jalali                      49260 non-null  object        \n",
      " 19  year                             49260 non-null  int16         \n",
      " 20  month                            49260 non-null  object        \n",
      " 21  season                           49260 non-null  object        \n",
      " 22  province                         49260 non-null  object        \n",
      " 23  temp_diff (°C)                   49260 non-null  float16       \n",
      " 24  remain_precipitation (mm)        49260 non-null  float16       \n",
      "dtypes: datetime64[ns](1), float16(17), int16(2), object(5)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# calling the function to clean datatype memory usage\n",
    "datatype_cleaner(df)\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d7a712274736468"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df.to_csv(\"Final Dataset.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b156f0fd956e468f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f27aaa339034fab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
